import os
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from Parser import parameter_parser  # Assuming you have a parser module

args = parameter_parser()

def parse_file(filename):
   
    with open(filename, "r", encoding="utf8") as file:
        fragment = []
        fragment_val = 0
        for line in file:
            stripped = line.strip()
            if not stripped:
                continue
            if "-" * 33 in line and fragment:
                yield fragment, fragment_val
                fragment = []
            elif stripped.split()[0].isdigit():
                if fragment:
                    if stripped.isdigit():
                        fragment_val = int(stripped)
                    else:
                        fragment.append(stripped)
            else:
                fragment.append(stripped)
    return fragment



def get_vectors_df_tfidf(filename, vector_length=300):
    fragments = []
    count = 0
    values = []
  

    # Create TfidfVectorizer with adjusted parameters
    vectorizer = TfidfVectorizer(max_features=vector_length, min_df=2, max_df=0.8)
    for fragment, val in parse_file(filename):
        count += 1
        print("Collecting fragments...", count, end="\r")
        fragments.append(" ".join(fragment))
        values.append(val)

    print()
    print("Training model...", end="\r")

    # Fit the vectorizer on all fragments
    try:
        X = vectorizer.fit_transform(fragments)
        print("Vocabulary size:", len(vectorizer.vocabulary_))
    except Exception as e:
        print("An error occurred during fitting:", e)

    # Prepare vectors using the same structure as Word2Vec and FastText
    vectors = []
    for fragment, val in zip(fragments, values):
        tfidf_vector = vectorizer.transform([fragment]).toarray().flatten()
        row = {"vector": tfidf_vector, "value": val}
        vectors.append(row)
    df = pd.DataFrame(vectors)
    return df



def get_df_tfidf():
    filename = args.dataset
    print("dataset:", filename)
    base = os.path.splitext(os.path.basename(filename))[0]
    vector_filename = base + "_TFIDF_fragment_vectors.pkl"
    vector_length = args.vector_dim
    
    if os.path.exists(vector_filename):
        df = pd.read_pickle(vector_filename)
    else:
        df = get_vectors_df_tfidf(filename, vector_length)
        df.to_pickle(vector_filename)

    return df, base

if __name__ == "__main__":
    df, base = get_df_tfidf()
    print("df:",df)
    print(df.head())  # Print the first few rows of the DataFrame
    print(df.shape)
    print (df.columns)
